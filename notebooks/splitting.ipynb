{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "%aimport gtree\n",
    "%aimport tools\n",
    "%aimport tree._my_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The goal of this notebook is to explore ways to optimizing our splitting algorithm, which is a huge part of the cost of this code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "\n",
    "class benchmark(object):\n",
    "\n",
    "    def __init__(self, msg, fmt=\"%0.3g\"):\n",
    "        self.msg = msg\n",
    "        self.fmt = fmt\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.start = timer()\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, *args):\n",
    "        t = timer() - self.start\n",
    "        print((\"%s : \" + self.fmt + \" seconds\") % (self.msg, t))\n",
    "        self.time = t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Foo\n",
      "Just A test : 0.00032 seconds\n"
     ]
    }
   ],
   "source": [
    "with benchmark(\"Just A test\"):\n",
    "    print \"Foo\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the 'alternative' split functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_loss(predicted, truth):\n",
    "    if len(truth) == 0:\n",
    "        return 0.0\n",
    "    else:\n",
    "        predicted = np.clip(predicted, 0.000001, .999999)  # predicted.clip(lower=0.000001, upper=.999999)  #  #\n",
    "        return (-1.0 * truth * np.log(predicted) - (1.0 - truth) * np.log(1.0 - predicted)).mean()\n",
    "\n",
    "    \n",
    "def leaf_good_rate_prediction_builder(_, target):\n",
    "\n",
    "    if len(target) > 0:\n",
    "        mean = target.sum() / len(target)  # sum(target) / len(target)\n",
    "    else:\n",
    "        mean = 0\n",
    "\n",
    "    return lambda fs: np.array([mean for _ in range(len(fs))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_by_col(fs, t, idx):\n",
    "    order = np.argsort(fs[:, idx])\n",
    "    return (fs[order], t[order])\n",
    "\n",
    "def _np_single_variable_best_split(df, var, target, loss_fn, leaf_prediction_builder, candidates=None):\n",
    "    X = df.values.copy()\n",
    "    Y = target.values.copy()\n",
    "    var_idx = list(df.columns).index(var)\n",
    "\n",
    "    # First, we sort the features by the ith idx\n",
    "    # order = np.argsort(df[:, var_idx])\n",
    "    # features = X[order]\n",
    "    # target = Y[order]\n",
    "    features, target = sort_by_col(X, Y, var_idx)\n",
    "    # IDX = df.index[order]\n",
    "    srs = X[:, var_idx]\n",
    "    if candidates is None:\n",
    "        candidates = _get_split_candidates(srs)\n",
    "\n",
    "        # candidates = set(srs)\n",
    "\n",
    "    best_loss = None\n",
    "    best_split = None\n",
    "\n",
    "    split_value = None\n",
    "\n",
    "    for idx in range(len(srs)):\n",
    "\n",
    "        # We consider splits only at the first value\n",
    "        # in a series\n",
    "        #  0  1  2  3  4  5  6  7  8\n",
    "        #  1  1  1  2  2  2  3  3  3\n",
    "        #           ^ --- SPLIT\n",
    "        #    [0:3]    [3:-1]\n",
    "        #\n",
    "        #\n",
    "        if srs[idx] == split_value:\n",
    "            continue\n",
    "        else:\n",
    "            split_value = srs[idx]\n",
    "\n",
    "        if split_value not in candidates:\n",
    "            continue\n",
    "\n",
    "        # left_condition = (srs < val)\n",
    "        np_feat_left = features[0:idx, :]\n",
    "        np_target_left = target[0:idx]\n",
    "\n",
    "        left_leaf_predict_fn = leaf_prediction_builder(np_feat_left, np_target_left)\n",
    "        left_predicted = left_leaf_predict_fn(np_feat_left)\n",
    "        left_loss = loss_fn(left_predicted, np_target_left)\n",
    "\n",
    "        # right_condition = (srs >= val)\n",
    "        np_feat_right = features[idx:len(X), :]\n",
    "        np_target_right = target[idx:len(X)]\n",
    "\n",
    "        right_leaf_predict_fn = leaf_prediction_builder(np_feat_right, np_target_right)\n",
    "        right_predicted = right_leaf_predict_fn(np_feat_right)\n",
    "        right_loss = loss_fn(right_predicted, np_target_right)\n",
    "\n",
    "        avg_loss = (left_loss * len(np_feat_left) + right_loss * (len(np_feat_right))) / (len(features))\n",
    "\n",
    "        # print \"Idx: {} Split Val: {:.3f} Left Loss: {:.3f} Right Loss: {:.3f} Avg Loss: {:.3f} Is Best?: {}\".format(\n",
    "        #    idx, split_value, left_loss, right_loss, avg_loss, avg_loss < best_loss\n",
    "        # )\n",
    "\n",
    "        if best_loss is None or avg_loss < best_loss:\n",
    "            best_split = split_value\n",
    "            best_loss = avg_loss\n",
    "\n",
    "    if best_loss is None:\n",
    "        raise Exception()\n",
    "\n",
    "    return best_split, best_loss\n",
    "\n",
    "\n",
    "def _hybrid_single_variable_best_split(df, var, target, loss_fn, leaf_prediction_builder, candidates=None):\n",
    "    X = df.values.copy()\n",
    "    Y = target.values.copy()\n",
    "    var_idx = list(df.columns).index(var)\n",
    "\n",
    "    # First, we sort the features by the ith idx\n",
    "    # order = np.argsort(df[:, var_idx])\n",
    "    # features = X[order]\n",
    "    # target = Y[order]\n",
    "    features, target = sort_by_col(X, Y, var_idx)\n",
    "    # IDX = df.index[order]\n",
    "    srs = X[:, var_idx]\n",
    "    if candidates is None:\n",
    "        candidates = _get_split_candidates(srs)\n",
    "\n",
    "        # candidates = set(srs)\n",
    "\n",
    "    best_loss = None\n",
    "    best_split = None\n",
    "\n",
    "    split_value = None\n",
    "\n",
    "    for idx in range(len(srs)):\n",
    "\n",
    "        # We consider splits only at the first value\n",
    "        # in a series\n",
    "        #  0  1  2  3  4  5  6  7  8\n",
    "        #  1  1  1  2  2  2  3  3  3\n",
    "        #           ^ --- SPLIT\n",
    "        #    [0:3]    [3:-1]\n",
    "        #\n",
    "        #\n",
    "        if srs[idx] == split_value:\n",
    "            continue\n",
    "        else:\n",
    "            split_value = srs[idx]\n",
    "\n",
    "        if split_value not in candidates:\n",
    "            continue\n",
    "\n",
    "        # left_condition = (srs < val)\n",
    "        np_feat_left = features[0:idx, :]\n",
    "        np_target_left = target[0:idx]\n",
    "        idx_left = df.index[0:idx]\n",
    "\n",
    "        df_feat_left = pd.DataFrame(np_feat_left, index=idx_left)\n",
    "        df_targ_left = pd.Series(np_target_left, index=idx_left)\n",
    "\n",
    "        left_leaf_predict_fn = leaf_prediction_builder(df_feat_left, df_targ_left)\n",
    "        left_predicted = left_leaf_predict_fn(df_feat_left)\n",
    "        left_loss = loss_fn(left_predicted, df_targ_left)\n",
    "\n",
    "        # right_condition = (srs >= val)\n",
    "        np_feat_right = features[idx:len(X), :]\n",
    "        np_target_right = target[idx:len(X)]\n",
    "        idx_right = df.index[idx:len(X)]\n",
    "\n",
    "        df_feat_right = pd.DataFrame(np_feat_right, index=idx_right)\n",
    "        df_targ_right = pd.Series(np_target_right, index=idx_right)\n",
    "\n",
    "        right_leaf_predict_fn = leaf_prediction_builder(df_feat_right, df_targ_right)\n",
    "        right_predicted = right_leaf_predict_fn(df_feat_right)\n",
    "        right_loss = loss_fn(right_predicted, df_targ_right)\n",
    "\n",
    "        avg_loss = (left_loss * len(np_feat_left) + right_loss * (len(np_feat_right))) / (len(features))\n",
    "\n",
    "        # print \"Idx: {} Split Val: {:.3f} Left Loss: {:.3f} Right Loss: {:.3f} Avg Loss: {:.3f} Is Best?: {}\".format(\n",
    "        #    idx, split_value, left_loss, right_loss, avg_loss, avg_loss < best_loss\n",
    "        # )\n",
    "\n",
    "        if best_loss is None or avg_loss < best_loss:\n",
    "            best_split = split_value\n",
    "            best_loss = avg_loss\n",
    "\n",
    "    if best_loss is None:\n",
    "        raise Exception()\n",
    "\n",
    "    return best_split, best_loss\n",
    "\n",
    "\n",
    "def _df_single_variable_best_split(df, var, target, loss_fn, leaf_prediction_builder, candidates=None):\n",
    "    # Convention:\n",
    "    # Left is BAD\n",
    "    # Right is GOOD\n",
    "\n",
    "    # TODO: Optimize me!\n",
    "    # Try: df.reindex_axis(index, copy=False)\n",
    "    # or:  df.reindex(index=['a', 'b'], copy=False)\n",
    "    # or even: df._reindex_axes(axes={'index':df.index, 'columns': df.columns},\n",
    "    # copy=False, level=None, limit=None, tolerance=None, method=None, fill_value=None)\n",
    "    # From generic.py: 2594\n",
    "\n",
    "\n",
    "    df = df.sort_values(by=var)\n",
    "    target = target.loc[df.index]\n",
    "\n",
    "    srs = df[var]\n",
    "\n",
    "    if candidates is None:\n",
    "        candidates = _get_split_candidates(srs)\n",
    "\n",
    "    if len(srs) <= len(candidates):\n",
    "        candidates = srs.values\n",
    "\n",
    "    best_loss = None\n",
    "    best_split = None\n",
    "\n",
    "    for idx in range(len(df)):\n",
    "\n",
    "        val = df.iloc[idx][var]\n",
    "\n",
    "        if val not in candidates:\n",
    "            continue\n",
    "\n",
    "        # left_idx = df.iloc[0, idx] #index[(srs <= val)]\n",
    "        df_left = df.iloc[0:idx]  # df.reindex_axis(left_idx, copy=False)  # df.loc[left_idx]\n",
    "        target_left = target.iloc[0:idx]\n",
    "        left_leaf_predict_fn = leaf_prediction_builder(df_left, target_left)\n",
    "        left_predicted = left_leaf_predict_fn(df_left)\n",
    "\n",
    "        # right_idx = df.index[(srs > val)]\n",
    "        df_right = df.iloc[idx:len(df)]  # reindex_axis(right_idx, copy=False)  # df.loc[right_idx]\n",
    "        target_right = target.iloc[idx:len(df)]  # .loc[right_idx]\n",
    "        right_leaf_predict_fn = leaf_prediction_builder(df_right, target_right)\n",
    "        right_predicted = right_leaf_predict_fn(df_right)\n",
    "\n",
    "        left_loss = loss_fn(left_predicted, target_left)\n",
    "        assert pd.notnull(left_loss), \"Loss yielded null value\"\n",
    "        right_loss = loss_fn(right_predicted, target_right)\n",
    "        assert pd.notnull(right_loss), \"Loss yielded null value\"\n",
    "\n",
    "        avg_loss = (left_loss * len(df_left) + right_loss * len(df_right)) / (len(df))\n",
    "\n",
    "        if best_loss is None or avg_loss < best_loss:\n",
    "            best_split = val\n",
    "            best_loss = avg_loss\n",
    "\n",
    "    return best_split, best_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigate Optimal Splitting\n",
    "\n",
    "Can we do splitting faster using raw numpy arrays rather than Pandas DataFrames?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features, df_targets = tools.make_random_classification(5000)\n",
    "df_features = pd.DataFrame(df_features, dtype='float32')\n",
    "df_targets = pd.Series(df_targets, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_feaures = np.array(df_features.values, dtype='float32')\n",
    "np_targets = np.array(df_targets.values, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = df_features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the candidates in advance\n",
    "candidate_map = {v: gtree._get_split_candidates(df_features[v]) for v in feature_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss_fn = gcross_entropy_loss\n",
    "#prediction_builder = gtree.leaf_good_rate_prediction_builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the numpy version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.300631523132324"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test Loss Function\n",
    "pred = pd.Series(df_targets, dtype=np.float32).values\n",
    "truth = np.zeros(len(df_targets), np.float32)\n",
    "\n",
    "tree._my_tree.CrossEntropyLoss().loss(truth, pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = 'feature_15'\n",
    "var_idx = 15\n",
    "candidates = set(candidate_map[var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.444324 0.692970100312\n",
      "GTREE DF Single : 0.856 seconds\n"
     ]
    }
   ],
   "source": [
    "with benchmark(\"GTREE DF Single\"):\n",
    "    s, l = _df_single_variable_best_split(\n",
    "            df_features, var, df_targets,\n",
    "            loss_fn=cross_entropy_loss,\n",
    "            leaf_prediction_builder=leaf_good_rate_prediction_builder,\n",
    "            candidates = candidates)\n",
    "    print s, l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.83052 0.692961128812\n",
      "GTREE HYBRID Single : 0.275 seconds\n"
     ]
    }
   ],
   "source": [
    "with benchmark(\"GTREE HYBRID Single\"):\n",
    "    s, l = _hybrid_single_variable_best_split(\n",
    "            df_features, var, df_targets,\n",
    "            loss_fn=cross_entropy_loss,\n",
    "            leaf_prediction_builder=leaf_good_rate_prediction_builder,\n",
    "            candidates = candidates)\n",
    "    print s, l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.83052 0.692961128812\n",
      "GTREE NP Single : 0.0972 seconds\n"
     ]
    }
   ],
   "source": [
    "with benchmark(\"GTREE NP Single\"):\n",
    "    s, l = _np_single_variable_best_split(\n",
    "            df_features, var, df_targets,\n",
    "            loss_fn=cross_entropy_loss, #gtree.error_rate_loss,\n",
    "            leaf_prediction_builder=leaf_good_rate_prediction_builder,\n",
    "            candidates = candidates)\n",
    "    print s, l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.00128457322717 5.64174222946\n",
      "NP CYTHON : 0.0227 seconds\n"
     ]
    }
   ],
   "source": [
    "with benchmark(\"NP CYTHON\"):\n",
    "    s, l = tree._my_tree.getBestSplit(\n",
    "        np_feaures,\n",
    "        var_idx,\n",
    "        np_targets,\n",
    "        tree._my_tree.CrossEntropyLoss(),\n",
    "        tree._my_tree.MeanLeafMapperBuilder(),\n",
    "        candidates)\n",
    "    print s, l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.63080155849 0.49979993701\n",
      "NP CYTHON ERROR RATE LOSS : 0.0131 seconds\n"
     ]
    }
   ],
   "source": [
    "#lmb = \n",
    "#ce = \n",
    "#spliter = tree._my_tree.SpitFinder()\n",
    "\n",
    "with benchmark(\"NP CYTHON ERROR RATE LOSS\"):\n",
    "    s, l = tree._my_tree.getBestSplit(\n",
    "        np_feaures,\n",
    "        var_idx,\n",
    "        np_targets,\n",
    "        tree._my_tree.ErrorRateLoss(),\n",
    "        tree._my_tree.MeanLeafMapperBuilder(),\n",
    "        candidates)\n",
    "    print s, l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.93952488899 0.029166419059\n",
      "NP CYTHON RANDOM LOSS : 0.0097 seconds\n"
     ]
    }
   ],
   "source": [
    "with benchmark(\"NP CYTHON RANDOM LOSS\"):\n",
    "    s, l = tree._my_tree.getBestSplit(\n",
    "        np_feaures,\n",
    "        var_idx,\n",
    "        np_targets,\n",
    "        tree._my_tree.RandomLoss(),\n",
    "        tree._my_tree.MeanLeafMapperBuilder(),\n",
    "        candidates)\n",
    "    print s, l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOT YET IMPLEMENTED\n",
    "\n",
    "lmb = tree._my_tree.MeanLeafMapperBuilder()\n",
    "ce = tree._my_tree.CrossEntropyLoss()\n",
    "#spliter = tree._my_tree.SpitFinder()\n",
    "\n",
    "with benchmark(\"SKLEARN ADAPTED\"):\n",
    "    s, l = spliter.getBestSplit(\n",
    "        var_idx,\n",
    "        candidates,\n",
    "        np_feaures,\n",
    "        np_targets,\n",
    "        lmb,\n",
    "        ce)\n",
    "    print s, l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with benchmark(\"NP NAIVE\"):\n",
    "#    s, l = np_naive_single_variable_best_split(\n",
    "#        features=np_feaures, var_idx=var_idx, target=np_targets,\n",
    "#        loss_fn=loss_fn, #gtree.error_rate_loss,\n",
    "#        leaf_prediction_builder=np_leaf_good_rate_split_builder,\n",
    "#        candidates=candidates)\n",
    "#    print s, l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with benchmark(\"NP SMART\"):\n",
    "#    s, l = np_single_variable_best_split(\n",
    "#        features=np_feaures, var_idx=15, target=np_targets,\n",
    "#        loss_fn=loss_fn, #gtree.error_rate_loss,\n",
    "#        leaf_prediction_builder=np_leaf_good_rate_split_builder,\n",
    "#        candidates=candidates)\n",
    "#    print s, l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(gtree.error_rate_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test multiple splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Df Splitting\n",
    "with benchmark(\"DF Test\"):\n",
    "    for var in feature_names:\n",
    "        gtree._df_single_variable_best_split(\n",
    "            df_features, var, df_targets,\n",
    "            loss_fn=loss_fn,\n",
    "            leaf_prediction_builder=prediction_builder,\n",
    "            candidates = candidate_map[var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with benchmark(\"NP Test\"):\n",
    "    for var in feature_names:\n",
    "        gtree._np_single_variable_best_split(\n",
    "            df_features, var, df_targets,\n",
    "            loss_fn=cross_entropy_loss,\n",
    "            leaf_prediction_builder=leaf_good_rate_prediction_builder,\n",
    "            candidates = candidate_map[var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lmb = tree._my_tree.MeanLeafMapperBuilder()\n",
    "ce = tree._my_tree.CrossEntropyLoss()\n",
    "#spliter = tree._my_tree.SpitFinder()\n",
    "\n",
    "with benchmark(\"NP CYTHON\"):\n",
    "    for i, var in enumerate(feature_names):\n",
    "        tree._my_tree.getBestSplit(\n",
    "            np_feaures,\n",
    "            i,\n",
    "            np_targets,\n",
    "            ce,\n",
    "            lmb,\n",
    "            set(candidate_map[var]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[1, 7, 3],\n",
    "              [4, 5, 6],\n",
    "              [7, 8, 9]])\n",
    "Y = np.array([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_by_col(X, Y, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.DataFrame({\n",
    "    'a': [1, 2, 3, 4, 3, 6],\n",
    "    'b': [10, 20, 30, 40, 50, 60]\n",
    "})\n",
    "y = pd.Series([1, 0, 0, 1, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import _criterion, _splitter\n",
    "\n",
    "c = _criterion.Gini(1, np.array([2]))\n",
    "s = _splitter.BestSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = len(df_features)\n",
    "\n",
    "splitter = s(c,\n",
    "             max_features,\n",
    "             min_samples_leaf=1,\n",
    "             min_weight_leaf=1,\n",
    "             random_state=1,\n",
    "             presort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.node_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.Series([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.index[[2, 0, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
