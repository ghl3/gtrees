{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "%aimport gtree\n",
    "%aimport tools\n",
    "%aimport tree._my_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The goal of this notebook is to explore ways to optimizing our splitting algorithm, which is a huge part of the cost of this code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "\n",
    "class benchmark(object):\n",
    "\n",
    "    def __init__(self, msg, fmt=\"%0.3g\"):\n",
    "        self.msg = msg\n",
    "        self.fmt = fmt\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.start = timer()\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, *args):\n",
    "        t = timer() - self.start\n",
    "        print((\"%s : \" + self.fmt + \" seconds\") % (self.msg, t))\n",
    "        self.time = t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Foo\n",
      "Just A test : 0.000241 seconds\n"
     ]
    }
   ],
   "source": [
    "with benchmark(\"Just A test\"):\n",
    "    print \"Foo\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigate Optimal Splitting\n",
    "\n",
    "Can we do splitting faster using raw numpy arrays rather than Pandas DataFrames?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features, df_targets = tools.make_random_classification(5000)\n",
    "df_features = pd.DataFrame(df_features, dtype='float32')\n",
    "df_targets = pd.Series(df_targets, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_feaures = np.array(df_features.values, dtype='float32')\n",
    "np_targets = np.array(df_targets.values, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = df_features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the candidates in advance\n",
    "candidate_map = {v: gtree._get_split_candidates(df_features[v]) for v in feature_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = gtree.cross_entropy_loss\n",
    "prediction_builder = gtree.leaf_good_rate_prediction_builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the numpy version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_leaf_good_rate_split_builder(features, target):\n",
    "    \"\"\"\n",
    "    Assume the target consists of 0, 1\n",
    "    \"\"\"\n",
    "    if len(target) > 0:\n",
    "        mean = sum(target) / len(target)\n",
    "    else:\n",
    "        mean = 0\n",
    "\n",
    "    return lambda arr: np.full(target.shape, mean) #pd.Series([mean for _ in range(len(df))], index=df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_naive_single_variable_best_split(features, var_idx, target, loss_fn, leaf_prediction_builder, candidates=None):\n",
    "\n",
    "    # Select the ith column\n",
    "    srs = features[:, var_idx]\n",
    "    if candidates is None:\n",
    "        candidates = list(srs) \n",
    "\n",
    "    best_loss = None\n",
    "    best_split = None\n",
    "\n",
    "    for val in candidates:\n",
    "        \n",
    "        #print srs, srs.shape\n",
    "        #print features, features.shape\n",
    "        \n",
    "        left_condition = (srs <= val)\n",
    "        # Get feature rows satisfying the constraint\n",
    "        feat_left = features[left_condition, :]\n",
    "        target_left = target[left_condition]\n",
    "        left_leaf_predict_fn = leaf_prediction_builder(feat_left, target_left)\n",
    "        left_predicted = left_leaf_predict_fn(feat_left)\n",
    "        left_loss = loss_fn(left_predicted, target_left)\n",
    "        #print \"LEFT PREDICTED: \", left_predicted\n",
    "        \n",
    "        right_condition = (srs > val)\n",
    "        # Get feature rows satisfying the constraint\n",
    "        feat_right = features[right_condition, :]\n",
    "        target_right = target[right_condition]\n",
    "        right_leaf_predict_fn = leaf_prediction_builder(feat_right, target_right)\n",
    "        right_predicted = right_leaf_predict_fn(feat_right)\n",
    "        right_loss = loss_fn(right_predicted, target_right)\n",
    "        #print \"RIGHT PREDICTED: \", right_predicted\n",
    "\n",
    "        #print \"Left loss: \", left_loss, \"Right Loss: \", right_loss\n",
    "        avg_loss = (left_loss * left_condition.sum() + right_loss * right_condition.sum()) / (len(features))\n",
    "        \n",
    "        if best_loss is None or avg_loss < best_loss:\n",
    "            best_split = val\n",
    "            best_loss = avg_loss\n",
    "\n",
    "    return best_split, best_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_by_col(fs, t, idx):\n",
    "    order = np.argsort(fs[:, idx])    \n",
    "    return (fs[order], t[order])\n",
    "\n",
    "def np_single_variable_best_split(features, var_idx, target, loss_fn, leaf_prediction_builder, candidates=None):\n",
    "\n",
    "    # First, we sort the features by the ith idx\n",
    "    features, target = sort_by_col(features, target, var_idx)\n",
    "    srs = features[:, var_idx]\n",
    "    if candidates is None:\n",
    "        candidates = set(srs) \n",
    "\n",
    "    best_loss = None\n",
    "    best_split = None\n",
    "    \n",
    "    split_value = None\n",
    "\n",
    "    for idx in range(len(srs)):\n",
    "        \n",
    "        # We consider splits only at the first value\n",
    "        # in a series\n",
    "        #  1 1 1 2 2 2 3 3 3\n",
    "        #       ^ -- SPLIT\n",
    "        #\n",
    "        if srs[idx] == split_value:\n",
    "            continue\n",
    "        else:\n",
    "            split_value = srs[idx]\n",
    "            \n",
    "        if split_value not in candidates:\n",
    "            continue\n",
    "        \n",
    "        #left_condition = (srs <= val)\n",
    "        feat_left = features[0:idx, :]\n",
    "        target_left = target[0:idx]\n",
    "        left_leaf_predict_fn = leaf_prediction_builder(feat_left, target_left)\n",
    "        left_predicted = left_leaf_predict_fn(feat_left)\n",
    "        left_loss = loss_fn(left_predicted, target_left)\n",
    "        \n",
    "        #right_condition = (srs > val)\n",
    "        feat_right = features[idx:-1, :]\n",
    "        target_right = target[idx:-1]\n",
    "        right_leaf_predict_fn = leaf_prediction_builder(feat_right, target_right)\n",
    "        right_predicted = right_leaf_predict_fn(feat_right)\n",
    "        right_loss = loss_fn(right_predicted, target_right)\n",
    "\n",
    "        avg_loss = (left_loss * idx + right_loss * (len(target)-idx)) / (len(features))\n",
    "        if best_loss is None or avg_loss < best_loss:\n",
    "            best_split = split_value\n",
    "            best_loss = avg_loss\n",
    "\n",
    "    return best_split, best_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.DataFrame({\n",
    "    'a': [1, 2, 3, 4, 3, 6],\n",
    "    'b': [10, 20, 30, 40, 50, 60]\n",
    "})\n",
    "y = pd.Series([1, 0, 0, 1, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = 'feature_15'\n",
    "var_idx = 15\n",
    "candidates = set(candidate_map[var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.08545 0.692860737821\n",
      "GTREE DF Single : 0.823 seconds\n"
     ]
    }
   ],
   "source": [
    "with benchmark(\"GTREE DF Single\"):\n",
    "    s, l = gtree._df_single_variable_best_split(\n",
    "            df_features, var, df_targets,\n",
    "            loss_fn=loss_fn, #gtree.error_rate_loss,\n",
    "            leaf_prediction_builder=prediction_builder,\n",
    "            candidates = candidates)\n",
    "    print s, l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.289631 0.692857644557\n",
      "GTREE HYBRID Single : 0.25 seconds\n"
     ]
    }
   ],
   "source": [
    "with benchmark(\"GTREE HYBRID Single\"):\n",
    "    s, l = gtree._hybrid_single_variable_best_split(\n",
    "            df_features, var, df_targets,\n",
    "            loss_fn=loss_fn, #gtree.error_rate_loss,\n",
    "            leaf_prediction_builder=prediction_builder,\n",
    "            candidates = candidates)\n",
    "    print s, l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.289631 0.692857644557\n",
      "GTREE NP Single : 0.0969 seconds\n"
     ]
    }
   ],
   "source": [
    "with benchmark(\"GTREE NP Single\"):\n",
    "    s, l = gtree._np_single_variable_best_split(\n",
    "            df_features, var, df_targets,\n",
    "            loss_fn=loss_fn, #gtree.error_rate_loss,\n",
    "            leaf_prediction_builder=prediction_builder,\n",
    "            candidates = candidates)\n",
    "    print s, l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split Idx:  3300 split val:  0.418152064085 Loss 0.693133592606\n",
      "Split Idx:  4100 split val:  0.922379493713 Loss 0.693139672279\n",
      "-1.0854524374 0.692860722542\n",
      "NP CYTHON : 0.0459 seconds\n"
     ]
    }
   ],
   "source": [
    "lmb = tree._my_tree.MeanLeafMapperBuilder()\n",
    "ce = tree._my_tree.CrossEntropyLoss()\n",
    "spliter = tree._my_tree.SpitFinder()\n",
    "\n",
    "with benchmark(\"NP CYTHON\"):\n",
    "    s, l = spliter.getBestSplit(\n",
    "        var_idx,\n",
    "        candidates,\n",
    "        np_feaures,\n",
    "        np_targets,\n",
    "        lmb,\n",
    "        ce)\n",
    "    print s, l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmb = tree._my_tree.MeanLeafMapperBuilder()\n",
    "ce = tree._my_tree.CrossEntropyLoss()\n",
    "spliter = tree._my_tree.SpitFinder()\n",
    "\n",
    "with benchmark(\"SKLEARN ADAPTED\"):\n",
    "    s, l = spliter.getBestSplit(\n",
    "        var_idx,\n",
    "        candidates,\n",
    "        np_feaures,\n",
    "        np_targets,\n",
    "        lmb,\n",
    "        ce)\n",
    "    print s, la\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with benchmark(\"NP NAIVE\"):\n",
    "#    s, l = np_naive_single_variable_best_split(\n",
    "#        features=np_feaures, var_idx=var_idx, target=np_targets,\n",
    "#        loss_fn=loss_fn, #gtree.error_rate_loss,\n",
    "#        leaf_prediction_builder=np_leaf_good_rate_split_builder,\n",
    "#        candidates=candidates)\n",
    "#    print s, l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with benchmark(\"NP SMART\"):\n",
    "#    s, l = np_single_variable_best_split(\n",
    "#        features=np_feaures, var_idx=15, target=np_targets,\n",
    "#        loss_fn=loss_fn, #gtree.error_rate_loss,\n",
    "#        leaf_prediction_builder=np_leaf_good_rate_split_builder,\n",
    "#        candidates=candidates)\n",
    "#    print s, l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test multiple splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DF Test : 86.1 seconds\n"
     ]
    }
   ],
   "source": [
    "# Test Df Splitting\n",
    "with benchmark(\"DF Test\"):\n",
    "    for var in feature_names:\n",
    "        gtree._df_single_variable_best_split(\n",
    "            df_features, var, df_targets,\n",
    "            loss_fn=loss_fn,\n",
    "            leaf_prediction_builder=prediction_builder,\n",
    "            candidates = candidate_map[var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NP Test : 10.9 seconds\n"
     ]
    }
   ],
   "source": [
    "with benchmark(\"NP Test\"):\n",
    "    for var in feature_names:\n",
    "        gtree._np_single_variable_best_split(\n",
    "            df_features, var, df_targets,\n",
    "            loss_fn=loss_fn,\n",
    "            leaf_prediction_builder=prediction_builder,\n",
    "            candidates = candidate_map[var])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[1, 7, 3],\n",
    "              [4, 5, 6],\n",
    "              [7, 8, 9]])\n",
    "Y = np.array([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_by_col(X, Y, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.DataFrame({\n",
    "    'a': [1, 2, 3, 4, 3, 6],\n",
    "    'b': [10, 20, 30, 40, 50, 60]\n",
    "})\n",
    "y = pd.Series([1, 0, 0, 1, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import _criterion, _splitter\n",
    "\n",
    "c = _criterion.Gini(1, np.array([2]))\n",
    "s = _splitter.BestSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = len(df_features)\n",
    "\n",
    "splitter = s(c,\n",
    "             max_features,\n",
    "             min_samples_leaf=1,\n",
    "             min_weight_leaf=1,\n",
    "             random_state=1,\n",
    "             presort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.node_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.Series([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.index[[2, 0, 1]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
