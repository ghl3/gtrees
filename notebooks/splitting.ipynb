{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "%aimport gtree\n",
    "%aimport tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "\n",
    "class benchmark(object):\n",
    "\n",
    "    def __init__(self, msg, fmt=\"%0.3g\"):\n",
    "        self.msg = msg\n",
    "        self.fmt = fmt\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.start = timer()\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, *args):\n",
    "        t = timer() - self.start\n",
    "        print((\"%s : \" + self.fmt + \" seconds\") % (self.msg, t))\n",
    "        self.time = t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Foo\n",
      "Just A test : 0.000242 seconds\n"
     ]
    }
   ],
   "source": [
    "with benchmark(\"Just A test\"):\n",
    "    \n",
    "    print \"Foo\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigate Optimal Splitting\n",
    "\n",
    "Can we do splitting faster using raw numpy arrays rather than Pandas DataFrames?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features, df_targets = tools.make_random_classification(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_feaures = df_features.values\n",
    "np_targets = df_targets.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = df_features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the candidates in advance\n",
    "candidate_map = {v: gtree._get_split_candidates(df_features[v]) for v in feature_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = gtree.cross_entropy_loss\n",
    "prediction_builder = gtree.leaf_good_rate_split_builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the numpy version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_leaf_good_rate_split_builder(features, target):\n",
    "    \"\"\"\n",
    "    Assume the target consists of 0, 1\n",
    "    \"\"\"\n",
    "    if len(target) > 0:\n",
    "        mean = sum(target) / len(target)\n",
    "    else:\n",
    "        mean = 0\n",
    "\n",
    "    return lambda arr: np.full(target.shape, mean) #pd.Series([mean for _ in range(len(df))], index=df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_naive_single_variable_best_split(features, var_idx, target, loss_fn, leaf_prediction_builder, candidates=None):\n",
    "\n",
    "    # Select the ith column\n",
    "    srs = features[:, var_idx]\n",
    "    candidates = list(srs) \n",
    "\n",
    "    best_loss = None\n",
    "    best_split = None\n",
    "\n",
    "    for val in candidates:\n",
    "        \n",
    "        #print srs, srs.shape\n",
    "        #print features, features.shape\n",
    "        \n",
    "        left_condition = (srs <= val)\n",
    "        # Get feature rows satisfying the constraint\n",
    "        feat_left = features[left_condition, :]\n",
    "        target_left = target[left_condition]\n",
    "        left_leaf_predict_fn = leaf_prediction_builder(feat_left, target_left)\n",
    "        left_predicted = left_leaf_predict_fn(feat_left)\n",
    "        left_loss = loss_fn(left_predicted, target_left)\n",
    "        #print \"LEFT PREDICTED: \", left_predicted\n",
    "        \n",
    "        right_condition = (srs > val)\n",
    "        # Get feature rows satisfying the constraint\n",
    "        feat_right = features[right_condition, :]\n",
    "        target_right = target[right_condition]\n",
    "        right_leaf_predict_fn = leaf_prediction_builder(feat_right, target_right)\n",
    "        right_predicted = right_leaf_predict_fn(feat_right)\n",
    "        right_loss = loss_fn(right_predicted, target_right)\n",
    "        #print \"RIGHT PREDICTED: \", right_predicted\n",
    "\n",
    "        #print \"Left loss: \", left_loss, \"Right Loss: \", right_loss\n",
    "        avg_loss = (left_loss * left_condition.sum() + right_loss * right_condition.sum()) / (len(features))\n",
    "        \n",
    "        if best_loss is None or avg_loss < best_loss:\n",
    "            best_split = val\n",
    "            best_loss = avg_loss\n",
    "\n",
    "    return best_split, best_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_by_col(fs, t, idx):\n",
    "    order = np.argsort(fs[:, idx])    \n",
    "    return (fs[order], t[order])\n",
    "\n",
    "def np_single_variable_best_split(features, var_idx, target, loss_fn, leaf_prediction_builder, candidates=None):\n",
    "\n",
    "    # First, we sort the features by the ith idx\n",
    "    print \"SORTING\"\n",
    "    features, target = sort_by_col(features, target, var_idx)\n",
    "    print \"DONE\"\n",
    "    srs = features[:, var_idx]\n",
    "    candidates = set(srs) \n",
    "\n",
    "    best_loss = None\n",
    "    best_split = None\n",
    "    \n",
    "    split_value = None\n",
    "\n",
    "    for idx in range(len(srs)):\n",
    "        \n",
    "        # We consider splits only at the first value\n",
    "        # in a series\n",
    "        #  1 1 1 2 2 2 3 3 3\n",
    "        #       ^ -- SPLIT\n",
    "        #\n",
    "        if srs[idx] == split_value:\n",
    "            continue\n",
    "        else:\n",
    "            split_value = srs[idx]\n",
    "            \n",
    "        if split_value not in candidates:\n",
    "            continue\n",
    "        \n",
    "        #left_condition = (srs <= val)\n",
    "        feat_left = features[0:idx, :]\n",
    "        target_left = target[0:idx]\n",
    "        left_leaf_predict_fn = leaf_prediction_builder(feat_left, target_left)\n",
    "        left_predicted = left_leaf_predict_fn(feat_left)\n",
    "        left_loss = loss_fn(left_predicted, target_left)\n",
    "        \n",
    "        #right_condition = (srs > val)\n",
    "        feat_right = features[idx:-1, :]\n",
    "        target_right = target[idx:-1]\n",
    "        right_leaf_predict_fn = leaf_prediction_builder(feat_right, target_right)\n",
    "        right_predicted = right_leaf_predict_fn(feat_right)\n",
    "        right_loss = loss_fn(right_predicted, target_right)\n",
    "\n",
    "        avg_loss = (left_loss * idx + right_loss * (len(target)-idx)) / (len(features))\n",
    "        if best_loss is None or avg_loss < best_loss:\n",
    "            best_split = split_value\n",
    "            best_loss = avg_loss\n",
    "\n",
    "    return best_split, best_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.DataFrame({\n",
    "    'a': [1, 2, 3, 4, 3, 6],\n",
    "    'b': [10, 20, 30, 40, 50, 60]\n",
    "})\n",
    "y = pd.Series([1, 0, 0, 1, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DF Single : 0.834 seconds\n"
     ]
    }
   ],
   "source": [
    "with benchmark(\"DF Single\"):\n",
    "    gtree._single_variable_best_split(\n",
    "            df_features, 'feature_15', df_targets,\n",
    "            loss_fn=loss_fn, #gtree.error_rate_loss,\n",
    "            leaf_prediction_builder=prediction_builder,\n",
    "            candidates = candidate_map[var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NP Single : 10.7 seconds\n"
     ]
    }
   ],
   "source": [
    "with benchmark(\"NP NAIVE\"):\n",
    "    np_naive_single_variable_best_split(\n",
    "        features=np_feaures, var_idx=15, target=np_targets,\n",
    "        loss_fn=loss_fn, #gtree.error_rate_loss,\n",
    "        leaf_prediction_builder=np_leaf_good_rate_split_builder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SORTING\n",
      "DONE\n",
      "NP SMART : 3.49 seconds\n"
     ]
    }
   ],
   "source": [
    "with benchmark(\"NP SMART\"):\n",
    "    np_single_variable_best_split(\n",
    "        features=np_feaures, var_idx=15, target=np_targets,\n",
    "        loss_fn=loss_fn, #gtree.error_rate_loss,\n",
    "        leaf_prediction_builder=np_leaf_good_rate_split_builder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DF Test : 3.45 seconds\n"
     ]
    }
   ],
   "source": [
    "# Test Df Splitting\n",
    "with benchmark(\"DF Test\"):\n",
    "    for var in feature_names[:5]:\n",
    "        gtree._single_variable_best_split(\n",
    "            df_features, var, df_targets,\n",
    "            loss_fn=loss_fn,\n",
    "            leaf_prediction_builder=prediction_builder,\n",
    "            candidates = candidate_map[var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NP Test : 17.2 seconds\n"
     ]
    }
   ],
   "source": [
    "with benchmark(\"NP Test\"):\n",
    "    for idx in range(df_features.shape[1])[:5]:\n",
    "        np_single_variable_best_split(\n",
    "            np_feaures, idx, np_targets,\n",
    "            loss_fn=loss_fn,\n",
    "            leaf_prediction_builder=np_leaf_good_rate_split_builder,\n",
    "            candidates = candidate_map[var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[1, 7, 3],\n",
    "              [4, 5, 6],\n",
    "              [7, 8, 9]])\n",
    "Y = np.array([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[4, 5, 6],\n",
       "        [1, 7, 3],\n",
       "        [7, 8, 9]]), array([2, 1, 3]))"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sort_by_col(X, Y, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.DataFrame({\n",
    "    'a': [1, 2, 3, 4, 3, 6],\n",
    "    'b': [10, 20, 30, 40, 50, 60]\n",
    "})\n",
    "y = pd.Series([1, 0, 0, 1, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import _criterion, _splitter\n",
    "\n",
    "c = _criterion.Gini(1, np.array([2]))\n",
    "s = _splitter.BestSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = len(df_features)\n",
    "\n",
    "splitter = s(c,\n",
    "             max_features,\n",
    "             min_samples_leaf=1,\n",
    "             min_weight_leaf=1,\n",
    "             random_state=1,\n",
    "             presort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-244-22ab8b1cb9af>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-244-22ab8b1cb9af>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    splitter.\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "splitter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'sklearn.tree._splitter.BestSplitter' has no attribute 'node_split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-247-114999d1fd8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'sklearn.tree._splitter.BestSplitter' has no attribute 'node_split'"
     ]
    }
   ],
   "source": [
    "s.node_split"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
